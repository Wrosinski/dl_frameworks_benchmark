{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretrainedmodels\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "from torchvision import models\n",
    "\n",
    "from models_pytorch import *\n",
    "from utils_pytorch import *\n",
    "from torch_dataset import BenchmarkDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'ResNet50'\n",
    "FIT_MAX_BATCH = True\n",
    "\n",
    "\n",
    "if FIT_MAX_BATCH:\n",
    "    if MODEL_NAME == 'DenseNet121':\n",
    "        MAX_BATCH_SIZE = 24\n",
    "    if MODEL_NAME == 'DenseNet169':\n",
    "        MAX_BATCH_SIZE = 16\n",
    "    if MODEL_NAME == 'Inception3':\n",
    "        MAX_BATCH_SIZE = 48\n",
    "    if MODEL_NAME == 'InceptionV4':\n",
    "        MAX_BATCH_SIZE = 32\n",
    "    if MODEL_NAME == 'InceptionResNetV2':\n",
    "        MAX_BATCH_SIZE = 16\n",
    "    if MODEL_NAME == 'NASNet':\n",
    "        MAX_BATCH_SIZE = 6\n",
    "    if MODEL_NAME == 'PNASNet':\n",
    "        MAX_BATCH_SIZE = 6\n",
    "    if MODEL_NAME == 'ResNet50':\n",
    "        MAX_BATCH_SIZE = 40\n",
    "\n",
    "if FIT_MAX_BATCH:\n",
    "    parameters_dict['BATCH_SIZE'] = MAX_BATCH_SIZE\n",
    "    print('Fit max batch size into memory.')\n",
    "\n",
    "\n",
    "parameters_dict = {\n",
    "    'MODEL_NAME': MODEL_NAME,\n",
    "    'NUM_SAMPLES': 1000,\n",
    "    'NUM_CHANNELS': 3,\n",
    "    'SIZE': 299,\n",
    "    'EPOCHS': 5,\n",
    "    'BATCH_SIZE': 40,\n",
    "    'NUM_RUNS': 5\n",
    "}\n",
    "\n",
    "\n",
    "NUM_SAMPLES = parameters_dict['NUM_SAMPLES']\n",
    "NUM_CHANNELS = parameters_dict['NUM_CHANNELS']\n",
    "SIZE = parameters_dict['SIZE']\n",
    "EPOCHS = parameters_dict['EPOCHS']\n",
    "BATCH_SIZE = parameters_dict['BATCH_SIZE']\n",
    "NUM_RUNS = parameters_dict['NUM_RUNS']\n",
    "\n",
    "\n",
    "input_dim = (NUM_SAMPLES, SIZE, SIZE, NUM_CHANNELS)\n",
    "print('parameters:\\n{}'.format(parameters_dict))\n",
    "print('\\ninput dim: {}'.format(input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.randint(0, 255, input_dim).astype(np.float32)\n",
    "y_train = np.expand_dims((np.random.rand(NUM_SAMPLES) > 0.5).astype(np.uint8), axis=-1).astype(np.float32)\n",
    "\n",
    "print('X: {}'.format(X_train.shape))\n",
    "print('y: {}'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BenchmarkDataset(\n",
    "    X_train, y_train)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "loss = torch.nn.BCELoss().cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_parameters = {\n",
    "    'num_classes': 1,\n",
    "    'pretrained': False,\n",
    "    'num_channels': 3,\n",
    "    'pooling_output_dim': 1,\n",
    "    'model_name': '',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_RUNS):\n",
    "    \n",
    "    run_name = '{}_size{}_batch{}_trial_{}'.format(MODEL_NAME, SIZE, BATCH_SIZE, i)\n",
    "    print('Running: {}\\n'.format(run_name))\n",
    "    \n",
    "    if not os.path.isdir('./logs/{}'.format(run_name)):\n",
    "        os.makedirs('./logs/{}'.format(run_name))\n",
    "    \n",
    "    pd.DataFrame.from_dict(parameters_dict, orient='index').to_csv(\n",
    "        './logs/{0}/{0}_parameters.csv'.format(run_name), header=None)\n",
    "\n",
    "    benchmark_model(train_loader,\n",
    "                    loss,\n",
    "                    model_parameters,\n",
    "                    MODEL_NAME, run_name,\n",
    "                    epochs=EPOCHS, \n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
